***

# 동시성 이슈 분석 및 해결 전략 보고서

**작성일:** 2025년 11월 28일  
**주제:** 멀티스레드 환경에서의 조회수 카운트 데이터 정합성 보장 및 성능 분석

---

## 1. 개요 (Overview)

본 보고서는 고동시성(High Concurrency) 환경에서 게시글 조회수 증가 로직을 수행할 때 발생하는 **데이터 불일치(Data Inconsistency)** 현상을 관측하고, 다양한 동시성 제어 기법을 적용하여 정합성과 성능 간의 트레이드오프(Trade-off)를 분석하는 것을 목적으로 한다.

### 1.1 테스트 환경
* **클라이언트:** 50개 스레드 동시 수행
* **요청 수:** 스레드 당 100회 호출 (Total: **5,000회** 요청)
* **지연 조건:** Race Condition 유발을 위해 로직 수행 중 `0.05초(50ms)`의 강제 지연(Sleep) 부여
* **대상 시스템:** 서버(Ubuntu24.04, Flask API Server, MySQL(DB), Redis(Cache)), 테스트 도구(Windows 10, Java 11)

---

## 2. 기본 구조 테스트 결과: 문제 상황 확인

동시성 제어 장치가 없는 초기 모델(Basic)에 대해 부하 테스트를 수행한 결과, 심각한 수준의 데이터 누락이 확인되었다.

### [cite_start]2.1 테스트 결과 데이터 (Baseline) [cite: 2]

| 구분 | 총 요청 수 | 평균 소요 시간 | Redis 최종 카운트 | **업데이트 유실률 (Loss Rate)** |
| :---: | :---: | :---: | :---: | :---: |
| **Basic** | 5,000 | 18,577 ms | **152** | **🔴 96.99%** |

### 2.2 현상 분석
* **데이터 정합성 :** 총 5,000번의 조회 요청이 발생했으나, 시스템에 반영된 수치는 평균 **152건**에 불과했다.
* **97%의 데이터 유실:** 전체 요청의 약 **96.99%**가 동시성 이슈로 인해 무시(Lost Update)되었다. 이는 서비스 운영이 불가능한 수준의 치명적인 결함이다.

---

## 3. 원인 분석: Race Condition과 타이밍 이슈

데이터 유실의 근본 원인은 **경쟁 상태(Race Condition)**로 인한 **갱신 분실(Lost Update)**이다.

### 3.1 발생 메커니즘 (Read-Modify-Write)
1.  **Read:** 스레드 A와 B가 거의 동시에 Redis에서 현재 값 `10`을 읽는다.
2.  **Gap (Timing Issue):** 애플리케이션 로직 수행 및 강제 지연(50ms) 동안, 두 스레드 모두 자신이 읽은 값(`10`)이 최신이라고 판단한다.
3.  **Write:**
    * 스레드 A가 `11` (`10+1`)을 저장한다.
    * 직후 스레드 B도 `11` (`10+1`)을 저장한다.
4.  **결과:** 실제로는 두 번의 증가 요청이 있었으나, 결과값은 `12`가 아닌 `11`이 되며 1회의 업데이트가 유실된다.

### 3.2 시사점
50개의 스레드에서 이러한 '덮어쓰기'가 빈번하게 발생하며, 카운트 데이터의 신뢰성을 확보하기 위해서는 별도의 제어도구 적용이 필수적이다.

---

## 4. 해결 전략별 테스트 결과 비교

[cite_start]데이터 불일치를 해결하기 위해 **Lock, Atomic(INCR), CAS, Write-Through, Double-Check** 5가지 전략을 적용하고 결과를 비교 분석하였다. [cite: 2, 3]

### 4.1 전략별 성능 비교 요약

| 해결 전략 | 평균 소요 시간(ms) | 정합성 (Redis 값) | 유실률 | 특징 및 분석 |
| :---: | :---: | :---: | :---: | :--- |
| **Basic (제어 없음)** | 18,577 | 152 | 96.99% | 정합성 실패. 사용 불가. |
| **Lock (Mutex)** | 270,883 | 5,000 | **0%** | 정합성은 완벽하나, **성능이 약 14.5배 저하**됨. 직렬화로 인한 병목 발생. |
| **CAS (Optimistic)** | 268,800 | 5,000 | **0%** | Lock과 유사하게 매우 느림. 잦은 충돌로 인한 **재시도(Retry) 오버헤드**가 원인. |
| **Atomic (INCR)** | **15,970** | 5,000 | **0%** | **가장 빠름.** Basic보다 오히려 빠르며 정합성 완벽 보장. |
| **Write-Through** | 16,372 | 5,000 | **0%** | Atomic과 대등한 성능. DB 갱신 후 캐시 처리로 구조적 안정성 확보. |
| **Double-Check** | 15,045 | 5,000 | **0%** | 가장 빠른 수치를 보였으나, 내부적으로 Atomic(INCR)을 혼합 사용하여 달성함. |

### 4.2 상세 분석
1.  **Lock & CAS (성능 이슈):** 50ms 지연 환경에서 Lock 방식은 스레드를 줄 세우고, CAS는 반복적인 재시도를 수행하느라 약 **4분 30초(270초)**가 소요되었다. 카운트 데이터의 신뢰는 확보하였으나, 처리되는 데이터양에 비해 많은 시간이 소비돼 실시간 서비스에 적용은 어려울 것으로 판단된다.
2.  **Atomic (INCR) (성능 최적):** Redis의 싱글 스레드 특성을 활용하여 애플리케이션 레벨의 잠금 없이 **약 16초** 만에 처리를 완료했다. 이는 Basic 모델(18.5초)보다도 빠른 수치로, 락 오버헤드가 없음을 증명한다.

---

## 5. 최종 해결 전략 선정 및 설계 이유

테스트 결과를 바탕으로 **"Atomic Operation (Redis INCR)"** 방식이 최적의 전략이라고 판단된다.
INCR의 경우, 어떤 쓰레드가 어떤 몇 번째로 수행됐느냐에 대한 부분은 관심을 갖지 않는다. 다만 요청에 따라 카운트를 증가시킬 뿐이다.
본 과제의 특성상 각 스레드들이 자신이 몇 번째인지에 대한 정보를 갖고 카운트 데이터로 기록 하는 방식이라면, INCR은 적합하지 않을 수 있다.
그러나 본 과제는 단순 카운트에 대한 부분만 해결하면 되기 때문에 INCR을 이용해 성능과 정합성을 모두 확보하는 방식이 적합하다고 판단된다.

### 5.1 선정 전략: Redis Atomic Increment
* **구현:** Redis가 제공하는 `INCR` 명령어를 사용하여 읽기-수정-쓰기 과정을 원자적(Atomic)으로 수행한다.
* **코드 예시:** `redis_client.incr(CACHE_KEY)`

### 5.2 설계 이유 (Rationale)
1.  **압도적인 성능:** Lock 방식 대비 약 **17배 빠른 처리 속도**를 기록하였다. (270s → 16s)
2.  **완벽한 정합성:** 테스트 결과 유실률 **0%**를 달성하여 데이터 무결성을 입증하였다.
3.  **구현의 단순성:** 복잡한 재시도 로직(CAS)이나 락 관리(Mutex) 없이, 단일 명령어로 동시성을 제어할 수 있어 유지보수에 유리하다.
4.  **시스템 부하 최소화:** 대기열(Waiting Queue)이나 스핀락(Spin Lock)으로 인한 CPU 점유가 발생하지 않는다.

---

## 6. 결론 (Conclusion)

본 실험을 통해 멀티스레드 환경에서의 단순 데이터 조작은 **97%에 달하는 데이터 유실**을 초래할 수 있음을 확인하였다.

이를 해결하기 위한 비교 실험 결과, **Redis의 Atomic Operation(INCR)**이 데이터의 정합성을 100% 보장하면서도 가장 우수한 성능을 발휘함을 입증하였다. 따라서, 조회수와 같이 빈번한 갱신이 발생하는 로직에는 **애플리케이션 레벨의 락(Lock)보다는 데이터 저장소(Redis/DB)가 제공하는 원자적 연산을 활용**하는 것이 성능과 안정성 측면에서 가장 적합한 설계 패턴이다.
